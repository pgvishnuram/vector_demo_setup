data_dir: ./vector/data
api:
  enabled: true
sources:
  generate_syslog:
    type: file
    include:
      - "./vector/data/*.log"
    #read_from: beginning

transforms:
  transform_syslog:
    type: add_fields
    inputs:
      - generate_syslog
    fields:
      component: test100
      workspace: test200
      release: test300

  my_transform_id:
    type: remap
    inputs:
      - generate_syslog
    source: |-
      . = parse_json!(.message)

  filter_task_log:
    type: filter
    inputs:
      - my_transform_id
    condition: .dag_id == "" || .dag_id != ""

  transform_task_log:
    type: remap
    inputs:
      - filter_task_log
    source: |-
      # Parse Syslog input. The "!" means that the script should abort on error.
      . = parse_json!(.message)
      .dag_id = "vishnuramnewdata"
      @timestamp = date
      .offset =  to_int(now()) * pow(10 , 9)

sinks:
  out:
    type: elasticsearch
    inputs:
      - transform_syslog
    mode: bulk
    compression: none
    endpoint: "http://localhost:9200"
    bulk:
      index: "vector.airflow.%Y-%m-%d"
      action: create

  task_log_out:
    type: elasticsearch
    inputs:
      - transform_task_log
    mode: bulk
    compression: none
    endpoint: "http://localhost:9200"
    #auth:
    #  strategy: "basic"
    #  user: astro001
    #  password : KNF3r6YFQsgV6FHoUY4kpkj6kZg60KYJ
    bulk:
      index: "vector.airflow.%Y-%m-%d"
      action: create
